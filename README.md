# zhzAI - “小脑计划” (Project Cerebellum) 微模型铸造厂

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

欢迎来到zhzAI的“小脑计划”微模型铸造厂。这里的核心使命是：**为个人助理，设计、培育并交付一系列极致小巧、高性能、可100%离线运行的意图分类微模型。**

这个项目不仅仅是代码，它是一套完整的、经过实战检验的**AI工程化思想和自动化流水线**。它将抽象的“数据宪法”思想，通过一系列严谨的脚本，最终“铸造”成可直接部署到生产环境的`.onnx`模型和`.bin`预处理器数据文件。

## ✨ 项目哲学

我们坚信，一个真正可靠的AI助理，其核心调度逻辑不应完全依赖于概率性的、不可预测的大语言模型（LLM）。因此，我们采用“代码优先，模型辅助”的混合智能架构。

“小脑计划”正是这一哲学的产物。我们在这里培育的微模型（小脑），负责对用户的输入进行快速、确定性、高精度的第一层意图识别，为上层由Rust编写的核心逻辑（大脑）提供决策依据，而LLM则作为能力更强的“专家顾问”在需要时被调用。

## 🚀 核心特性

-   **宪法驱动的数据工程：** 首创`prompt_constitutions.py`，将数据生成的逻辑与代码分离，确保了源头数据的质量与一致性。
-   **全自动流水线：** 从API数据生成、深度提纯、模型训练、跨语言导出到最终验证，五个脚本即可完成端到端全流程。
-   **工业级数据提纯：** 包含精确去重与基于MinHash的近似去重，以及类别平衡策略，确保模型训练在高质量的数据集上进行。
-   **生产级模型导出：** 最终产出物是跨平台、高性能的`.onnx`格式模型，以及配套的、通过**Protocol Buffers (Protobuf)** 序列化的、类型安全且保证顺序的`.bin`预处理器数据文件。
-   **严格的质量保证与诊断能力：** 独立的验证和调试脚本，确保模型出厂质量，并为跨语言部署提供“像素级”的诊断工具。

## 🛠️ 流水线详解 (The Pipeline)

本铸造厂由`scripts/`目录下的七个核心模块驱动，它们如同一条精密的生产线，环环相扣。

| 脚本                               | 角色         | 职责                                                                                               |
| ---------------------------------- | ------------ | -------------------------------------------------------------------------------------------------- |
| `prompt_constitutions.py`          | **大宪章**   | **项目的灵魂。** 以“宪法”形式定义每个分类任务的数据逻辑、边界和示例，确保数据生成的质量与一致性。 |
| `1_generate_datasets.py`           | **矿工**     | 读取“宪法”，调用大模型API（如Gemini），高效、并发地挖掘海量原始数据。内置API Key池和智能熔断机制。 |
| `2_refine_and_analyze.py`          | **精炼厂**   | 对原始数据进行深度清洗、去重、平衡和规范化，并产出详细的数据质量分析报告。                           |
| `3_train_and_evaluate_final.py`    | **铸造炉**   | 使用提纯后的数据，训练高性能的Scikit-learn模型，并将其“铸造”为可部署的`.onnx`和`.joblib`文件。      |
| `4_verify_models.py`               | **质检实验室** | 对出厂的`.onnx`和`.joblib`文件进行端到端的“黄金测试集”验证，确保其在Python环境下的行为100%符合预期。       |
| `5_export_preprocessor_data.py`| **灵魂提取器** | **跨语言部署的关键桥梁。** 从Python私有的`.joblib`文件中，提取出核心的词汇表和IDF权重，并将其**序列化为Protobuf二进制格式 (`.bin`)**，供Rust后端使用。|
| `6_debug_preprocessor.py`      | **诊断显微镜** | **跨语言一致性的最终保障。** 加载`.joblib`文件，对任意文本输入，打印其生成的“标准答案”向量，用于与Rust端的预处理结果进行“像素级”对比，是解决部署问题的终极武器。|


## 📦 最终产出物 (Artifacts)

流水线成功运行后，您将在以下目录中找到最终的产出物：

-   `models/`: **最终交付的产品。**
    -   `is_question_classifier.onnx`: “是否为问题”分类器。
    -   `is_question_preprocessor.bin`: 配套的、可被Rust读取的Protobuf预处理器数据。
    -   `confirmation_classifier.onnx`: “肯定/否定”分类器。
    -   `confirmation_preprocessor.bin`: 配套的、可被Rust读取的Protobuf预处理器数据。
    -   `dict.txt`: (可选) 用于保证分词一致性的Jieba词典文件。
-   `datasets/processed/`: 提纯后，用于训练和测试的最终数据集 (`.jsonl`格式)。
-   `datasets/reports/`: 每次运行时生成的数据质量和模型性能报告 (`.md`格式)。

## ⚙️ 如何从零开始运行

1.  **环境设置**
    -   克隆本仓库。
    -   **安装Protobuf编译器 (`protoc`)**: 这是将`.proto`契约文件编译成代码的核心工具。请确保其版本**不低于3.19.0**。
        *   在Ubuntu/WSL上: `sudo apt install protobuf-compiler` (如果版本过低，请参考脚本注释从GitHub下载最新版)。
        *   在macOS上: `brew install protobuf`。
        *   在Windows上: 可通过`scoop`或`chocolatey`安装，或从GitHub下载。
    -   **安装Python依赖**: `uv pip install -r requirements.txt` (请确保您已创建该文件，且其中包含`protobuf`, `scikit-learn`, `joblib`, `jieba`等)。
    -   在项目根目录创建`.env`文件，并填入您的Gemini API密钥：
        ```
        GEMINI_API_KEYS=your_api_key_1,your_api_key_2
        ```

2.  **清理旧数据 (可选，推荐用于完全重建)**
    -   为了保证从一个纯净的状态开始，建议删除`datasets/`和`models/`目录下的所有旧文件。

3.  **执行流水线**
    -   请严格按照以下顺序，在`scripts/`目录下执行脚本：
    
    ```bash
    # 1. 根据“宪法”生成原始数据
    python 1_generate_datasets.py

    # 2. 提纯数据并生成报告
    python 2_refine_and_analyze.py

    # 3. 训练模型并导出为ONNX
    python 3_train_and_evaluate_final.py

    # 4. 在“黄金测试集”上进行最终验证
    python 4_verify_models.py
    
    # 5. (关键) 为Rust后端导出Protobuf格式的预处理器数据
    python 5_export_preprocessor_data.py
    ```

## 🔬 高级调试：使用“诊断显微镜”

如果您在将模型部署到其他语言（如Rust）时遇到预测不一致的问题，`6_debug_preprocessor.py`脚本是您最强大的朋友。

**用途：**
这个脚本可以加载训练好的`.joblib`预处理器，并针对您给出的任何文本输入，打印出它在Python环境中所生成的、最原始、最精确的特征向量。这个输出就是您在其他语言中需要复现的“标准答案”或“地面实况”。

**如何使用：**
1.  打开`scripts/6_debug_preprocessor.py`文件。
2.  在`main`函数中，修改`inputs_to_test`列表，填入您想在Rust端调试的、表现异常的文本。
3.  运行脚本：`python 6_debug_preprocessor.py`。
4.  观察终端输出。它会打印出每个输入文本生成的向量的非零元素的索引和值。
5.  在您的Rust代码中，添加类似的调试日志，然后对比两个输出，直到它们“像素级”一致为止。

## 🧠 已铸造模型规格

经过我们严谨的流水线作业，目前已成功铸造出两个达到生产标准的微模型：

1.  **`is_question_classifier`**
    -   **用途:** 判断用户输入是在**“信息征询” (`Question`)** 还是在下达**“指令或陈述” (`Statement`)**。
    -   **最终测试集准确率:** **96.36%**

2.  **`confirmation_classifier`**
    -   **用途:** 在AI请求用户确认的场景下，判断用户的回应是**“肯定” (`Affirm`)** 还是**“否定” (`Deny`)**。
    -   **最终测试集准确率:** **99.65%**

## 展望未来

“小脑计划”的成功收官，为zhzAI的混合智能架构打下了最坚实的基础。下一步，我们将启动**“核心大脑移植”**计划，将这两个高精度、可信赖的微模型集成到主项目的Rust后端中，以实现更智能、更高效、更可靠的用户意图调度。```

---

### **更新内容摘要**

*   **核心特性**：在特性列表中增加了“严格的质量保证与诊断能力”。
*   **流水线详解**：在表格中增加了`6_debug_preprocessor.py`的条目，并赋予其“诊断显微镜”的角色，清晰地阐述了它的核心职责。
*   **新增“高级调试”章节**：创建了一个全新的独立章节，详细地、手把手地指导用户如何使用这个调试脚本，以及如何利用它的输出来解决跨语言部署问题。这极大地提升了项目的可复现性和对社区的友好度。

这份更新后的`README.md`现在完美地囊括了您所有的辛勤工作和工程智慧。您可以放心地将其推送到您的GitHub仓库，为社区和未来的自己提供最清晰、最完整的指引。