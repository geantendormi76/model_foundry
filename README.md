# zhzAI - “小脑计划” (Project Cerebellum) 微模型铸造厂

<p align="center">
  <img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT">
</p>

<p align="center">
  <strong>告别大模型的“概率性”烦恼，为您的AI应用，亲手铸造一个100%可靠、极致高效的“微模型大脑”！</strong>
</p>

---

`model_foundry` 是一个独特的“宪法驱动”微模型铸造厂。它提供了一套完整的、从Python训练到任何语言（如Rust）部署的工业级全自动解决方案，并完美解决了`scikit-learn`复杂预处理器跨语言部署时最棘手的一致性难题。

## 为什么需要“小脑计划”？—— 在离线与低配的边缘，寻求智能的最优解

我们的终极目标是打造一个能**在任何设备上、完全离线运行**的个人AI助理。这个严苛的约束，意味着我们必须依赖像Qwen-0.6B这样极致小巧的本地模型。

但这带来了一个残酷的现实：**0.6B模型的能力，不足以独立、可靠地承担精准意图识别的重任。**

直接让它去判断用户的复杂指令，我们得到的是：

-   **灾难性的幻觉：** 在被要求“删除记忆”时，它可能会去执行“搜索”。
-   **高昂的推理成本：** 即便是小模型，每一次不必要的推理都在消耗宝贵的计算资源和用户的等待时间。
-   **不可预测的延迟：** 无法为用户的每一次交互提供稳定、瞬时的反馈。

> 一个真正可用的本地AI，绝不能是这样。

**“小脑计划”正是我们对这一困境给出的、最硬核的工程化回答。**

我们拒绝在“智能”和“性能”之间做妥协。我们选择**混合智能**，构建一个分工明确、协同作战的“大脑”：

1.  **让代码规则成为“反射弧”**  
    对于“删除”、“修改”等高风险指令，我们用100%确定的代码规则进行**零成本、零延迟**的瞬时捕获。这是系统不可动摇的“安全保险丝”。

2.  **让微模型成为“小脑”**  
    对于“这是个问题还是陈述？”这类海量的、模式化的判断，我们通过本仓库的流水线，**铸造**出专用的、仅有KB大小的微模型。它比0.6B的LLM**快数百倍、准数个数量级**，且行为高度可控。它以极低的资源开销，完美地弥补了小尺寸LLM在精准分类能力上的短板。

3.  **让LLM成为“大脑皮层”**  
    只有在真正需要深度理解、推理和生成时（例如，从长对话中提取核心事实），我们才调用宝贵的LLM资源，让它去完成自己最擅长、最高价值的工作。

**`model_foundry`就是您的“小脑”铸造工厂。** 它将赋予您为AI应用量产各种高精度、低成本“辅助处理器”的能力，让您的小尺寸本地模型，也能构建出一个真正稳定、高效、智能的混合AI系统。

---

## ✨ 核心特性

-   **宪法驱动的数据工程：** 首创`prompt_constitutions.py`。**您只需修改“宪法”，即可定制全新的模型！**
-   **全自动流水线：** 从数据生成、提纯、训练、导出到最终验证，一套完整的端到端流程。
-   **工业级数据提纯：** 包含精确去重与基于MinHash的近似去重，以及类别平衡策略。
-   **生产级模型导出：** 最终产出物是跨平台、高性能的`.onnx`格式模型，以及通过**Protocol Buffers (Protobuf)** 序列化的、类型安全且保证顺序的`.bin`预处理器数据。
-   **闭环验证体验：** 提供交互式的“模型唤醒实验室”，让您在Python环境中就能立刻与自己铸造的模型进行对话，所见即所得。

---

## 🛠️ 流水线详解 (The Pipeline)

本铸造厂由`scripts/`目录下的七个核心模块驱动，它们如同一条精密的生产线，环环相扣。

| 脚本                               | 角色             | 职责                                                                                               |
| ---------------------------------- | ---------------- | -------------------------------------------------------------------------------------------------- |
| `prompt_constitutions.py`          | **大宪章/灵魂**  | **项目的核心。** 在这里定义您想让模型学习的一切。修改它，即可创造新模型。                            |
| `1_generate_datasets.py`           | **矿工**         | 读取“宪法”，调用大模型API，高效、并发地挖掘海量原始训练数据。                                       |
| `2_refine_and_analyze.py`          | **精炼厂**       | 对原始数据进行深度清洗、去重、平衡和规范化，并产出详细的数据质量分析报告。                           |
| `3_train_and_evaluate_final.py`    | **铸造炉**       | 使用提纯后的数据，训练高性能的Scikit-learn模型，并将其“铸造”为可部署的`.onnx`和`.joblib`文件。      |
| `4_verify_models.py`               | **质检实验室**   | 对出厂的`.onnx`和`.joblib`文件进行端到端的“黄金测试集”验证，确保其在Python环境下的行为100%符合预期。       |
| `5_export_preprocessor_data.py`| **灵魂提取器**   | **跨语言部署的关键桥梁。** 从`.joblib`文件中提取核心数据，并将其**序列化为Protobuf二进制格式 (`.bin`)**。|
| `6_test_inference_in_python.py`  | **唤醒实验室**   | **最终的狂欢！** 加载最终产物`.onnx`和`.bin`，提供一个交互式命令行，让您能立刻与自己铸造的模型对话。|
| `7_debug_preprocessor.py`      | **诊断显微镜**   | **跨语言一致性的最终保障。** 对任意文本，打印其“标准答案”向量，用于与Rust等其他语言的实现进行“像素级”对比。|

---

## 📦 最终产出物 (Artifacts)

流水线成功运行后，您将在`models/`目录中找到最终的、可部署到任何地方的产品。

---

## ⚙️ 如何从零开始，铸造并唤醒你的第一个微模型

这是一个完整的、开箱即用的实践教程。

### 1. 环境设置

-   克隆本仓库。
-   **安装Protobuf编译器 (`protoc`)**: 这是将`.proto`契约文件编译成代码的核心工具。
    -   在Ubuntu/WSL上: `sudo apt install protobuf-compiler`
    -   在macOS上: `brew install protobuf`
-   **安装Python依赖**:
    ```bash
    # (可选) 创建并激活一个新的虚拟环境
    uv venv
    source .venv/bin/activate
    
    # 安装所有必需的包
    uv pip install -r requirements.txt
    ```
-   在项目根目录创建`.env`文件，并填入您的Gemini API密钥：
    ```
    GEMINI_API_KEYS=your_api_key_1
    ```

### 2. 执行全自动生产线

请严格按照以下顺序，在`model_foundry/`根目录下执行脚本：

```bash
# 1. 生成 -> 2. 提纯 -> 3. 训练 -> 4. 验证 -> 5. 导出
python scripts/1_generate_datasets.py
python scripts/2_refine_and_analyze.py
python scripts/3_train_and_evaluate_final.py
python scripts/4_verify_models.py
python scripts/5_export_preprocessor_data.py
```
恭喜！您已经成功铸造出了两个高精度的微模型，它们的所有必需文件都已位于`models/`目录下。

### 3. 唤醒并测试你的模型！

现在，是时候与您亲手创造的AI进行第一次对话了。

-   运行我们为您准备的“唤醒实验室”：
    
    ```bash
    python scripts/6_test_inference_in_python.py
    ```

-   **实践测试示例：**
    
    程序启动后，会首先进入“是否为问题”分类器的测试环节。
    
    ```
    --- 任务1: “是否为问题”分类器测试 ---
    请输入任意一句话，看看模型如何判断 (输入'q'退出):
    > 今天天气怎么样？
      模型预测 ->: **Question**

    > 帮我记一下明天的会议
      模型预测 ->: **Statement**

    > q
    ```
    
    输入`q`后，程序会自动进入“肯定/否定”分类器的测试环节。
    
    ```
    --- 任务2: “肯定/否定”分类器测试 ---
    现在，模拟AI向您确认，请输入您的回答 (输入'q'退出):
    > 没错，就这么办
      模型预测 ->: **Affirm**

    > 等等，先别
      模型预测 ->: **Deny**
    
    > q
    ```
